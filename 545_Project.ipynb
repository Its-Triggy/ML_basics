{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ax0vBPmH6ar7"
   },
   "source": [
    "### Introduction\n",
    "We are looking to predict the star rating (0-5 stars) assiciated with a particular Amazon review. \n",
    "To do this we are going to use Machine Learning (ML). ML learns how to make predictions by learning from training data. Once the ML model is trained, it can predict the output for a given input based on the previous data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FJQHIjmwEc8n"
   },
   "source": [
    "We will try out a number of ML models to see which one is best at predicting Amazon review star-ratings. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CPmMuvXo7BpR"
   },
   "source": [
    "### Installing, Importing, and Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mrg3ilyX7Efh"
   },
   "source": [
    "We can start by installing and importing some libraries that will help us with our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nB-65mi_PQEu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%capture` not found.\n"
     ]
    }
   ],
   "source": [
    "#Install stuff\n",
    "%%capture\n",
    "!pip install -U gensim\n",
    "!pip install urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ngg1pmoZPQE4"
   },
   "outputs": [],
   "source": [
    "#Import stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LsiModel, KeyedVectors\n",
    "from gensim.models.tfidfmodel import TfidfModel\n",
    "from gensim.models.nmf import Nmf\n",
    "\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from datetime import *\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3s_7J_AepFhG"
   },
   "source": [
    "Now we can load the data. The data we are using are amazon reviews, and their corresponding star rating from 0-5. The reviews are stored as \"bags of words\" (BoW), meaning word order is not retained. We are assuming the word order will not be critical to making good estimations. Let's see if that assumption is valid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79R84xo4FESL"
   },
   "outputs": [],
   "source": [
    "#Access data\n",
    "%%capture\n",
    "!wget https://cis.upenn.edu/~cis545/data/reviews.dict\n",
    "!wget https://cis.upenn.edu/~cis545/data/train_reviews.mm\n",
    "!wget https://cis.upenn.edu/~cis545/data/train_times.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBLPPKcePQE9"
   },
   "outputs": [],
   "source": [
    "#Store data in variables\n",
    "reviews_dict = corpora.Dictionary.load(\"reviews.dict\")\n",
    "reviews_bow = corpora.MmCorpus('train_reviews.mm')\n",
    "reviews_times  = np.load('train_times.npy')\n",
    "reviews_times.shape = (len(reviews_bow),1)\n",
    "y = np.vstack((np.repeat(1, 4000), np.repeat(2, 4000), np.repeat(3, 4000), np.repeat(4, 4000), np.repeat(5, 4000)))\n",
    "y = np.repeat(y, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iw7zBjAm6Qyp",
    "nbgrader": {
     "grade": false,
     "grade_id": "spec-1-1-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### PCA\n",
    "We want to start training machine learning models with our data, however right now the number of features is simply too large. We can use a process called Principal Component Analysis (PCA) to separate out the orthogonal vectors, and then we'll trim those that have basiclly no impact. This is analogous to Taylor Series approximation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0nxd1BT6QPj"
   },
   "source": [
    "We don't yet know how many of these orthogonal components we want. Let's narrow down exactly where we stop gaining predictive power by training some ML models with different numbers of components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zxP1dxBZHZR6"
   },
   "source": [
    "In order to do this, we will need a function that converts sparse data into dense data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0hhoUvIZpr4d",
    "nbgrader": {
     "grade": false,
     "grade_id": "spec-2-0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Densify a Sparse Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huP8ANar8dAq"
   },
   "source": [
    "Dense data contains the frequency for every word present in the sentence and a 0 for every other word, whereas sparse data contains only a frequency for every word in the sentence and does not mention the other words. This helps prevent storing and modifying overly large variables, but is not what we want in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuzFAAekPQId",
    "nbgrader": {
     "grade": false,
     "grade_id": "answer-2-1",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "def densify(sparse, columns):\n",
    "    dense = np.zeros((len(sparse), columns)) #Fill up the array with zeros\n",
    "    \n",
    "    #Fill in the frequency for those that have it\n",
    "    for i, sentence in enumerate(sparse):\n",
    "      for word in sentence:\n",
    "        dense[i, word[0]] += word[1]\n",
    "    return(dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xL-AUBK283lS"
   },
   "source": [
    "###How we will evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qjmHwuf-H8QE"
   },
   "source": [
    "For whatever model we try, we want to know how many components are ideal for our analysis, so we will evaluate the model several times using different reconstructed matrices of up 200 components using accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Os7QqbgVp2bI"
   },
   "source": [
    "This function trains a given model (labeled eval_model) and evaluates its performance. We won't use this function by itself though, we will have another function call it several times using different matrices so we can compare them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "acWFX8EsrCdM",
    "nbgrader": {
     "grade": false,
     "grade_id": "answer-3-1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Returns the accuracy score fo a model given data\n",
    "def evaluate_model(X, y, eval_model):\n",
    "    X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 1911)    \n",
    "    eval_model.fit(X_train, y_train)\n",
    "    return eval_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XIy40pHYrClZ",
    "nbgrader": {
     "grade": false,
     "grade_id": "spec-3-2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This function compares the performance of different matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsfJ3KIglY-S",
    "nbgrader": {
     "grade": false,
     "grade_id": "answer-3-2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Compares the peformance of different input matrices \n",
    "def evaluate_cutoffs(X_orig, X_dict, y, cutoffs, eval_model):\n",
    "    results = []\n",
    "    \n",
    "    #Create a new model for each cutoff\n",
    "    for i, cutoff in enumerate(cutoffs):\n",
    "        print(i+1, \"of\", len(cutoffs),\"...\")\n",
    "        np.random.seed(1911)\n",
    "    \n",
    "        model = LsiModel(X_orig, num_topics=cutoff, id2word=X_dict)\n",
    "        V = densify(model[X_orig], len(model.projection.s))\n",
    "        \n",
    "        #Store the results for the model\n",
    "        result = evaluate_model(V, y, eval_model)\n",
    "        results.append(result)\n",
    "    \n",
    "    #Plot the results\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('# of Components')\n",
    "    plt.title('PCA Analysis')\n",
    "    plt.style.context('seaborn-whitegrid')\n",
    "    plt.plot(cutoffs, results)\n",
    "\n",
    "    #Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnrTmdJSL-Tt"
   },
   "source": [
    "### Let's evaluate or first model: Random Forest! This will be the first of several that we test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n6Wrw13-SXbE",
    "nbgrader": {
     "grade": false,
     "grade_id": "spec-3-2-1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we can get an idea for how the number of principal components affects our model's accuracy. To do this, we need to pick a model. Let's start with a random forest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Nrs2CVl9cAT"
   },
   "source": [
    "A random forest consists of several decision trees trained on different sections of the data, and their predictions are averaged. This can solve some of the overfitting issues that come with decision trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDAI7SAWbD1K"
   },
   "outputs": [],
   "source": [
    "eval_model = RandomForestClassifier(n_estimators=70, random_state=1911)\n",
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(20,220,20), eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnBMppVMJ3EX"
   },
   "source": [
    "It looks like the model accuracy already started plateauing even before 20 components. Let's see what was happening before... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hYWFc8sKxAY"
   },
   "outputs": [],
   "source": [
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(2,22,2), eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfoNExP4yDvL"
   },
   "source": [
    "The plateauing begins as soon as just 10-12 components! This model accurately predicts the star value of a review ~65% of the time. Not bad! Let's see how other models compare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOdyYZSCpPyk"
   },
   "source": [
    "### Decision Tree!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75FQLPXKpRt2"
   },
   "source": [
    "Are be being overly complicated here? Would a simple decision tree model do the trick, or would it overfit the data, as it is prone ot do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cds_Mf_dgoDH"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "eval_model = tree.DecisionTreeClassifier()\n",
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(20,420,20), eval_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G9k2IG3CpdDB"
   },
   "source": [
    "Certainly not the way to go. It can predict the correct outcome about half of the time, but this is a serious degredation for the success rates of our previous models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_9ONgd5ppvIk"
   },
   "source": [
    "###Decision Stumps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I7PAGjiipxXs"
   },
   "source": [
    "There are otherways to avoid the overfitting, however. What if we make a decision tree that only went so far, say to a depth of only 3? Sometimes a more general decision is better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuNp8O0ig2K0"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "eval_model = tree.DecisionTreeClassifier(max_depth=3)\n",
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(20,420,20), eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ekSEPqPJqI71"
   },
   "source": [
    "But not always a better result! We still are getting very low accuracy, right around 50%. Forget that! The random forest is so far the best model still. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkHO6eZUqPDq"
   },
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_IEpujfqRcN"
   },
   "source": [
    "Enough with the trees! Our next model, Naive Bayes, will predict the most likely output for an input given the data we've seen so far using statistical modelling. This is a good general model but may be limited in success on a bag of words model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BS_3_XKAhFVM"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "eval_model = GaussianNB()\n",
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(20,420,20), eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P8D8UtKr1KjA"
   },
   "source": [
    "The results just got worse and worse with more components, never doing better than around 38%. I'd say this is definitely not the direction to go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCK50dCSblkf"
   },
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eFm8kuAo-FyL"
   },
   "source": [
    "A perceptron is like a two layered Neuran Network (NN) with just input nodes and an output node. This is a simple yet powerful ML model, let's see how it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJ8tMIQtbnn-"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "eval_model = Perceptron(tol=1e-3, random_state=0)\n",
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(20,420,20), eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QGvCuSchmmb"
   },
   "source": [
    "The percepton takes longer to converge, at around 100 components. However the accuracy is improved to 70+%. Best so far! Can we do even better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8DG3TykOM59H"
   },
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2Mb4bCqbBMC"
   },
   "source": [
    "Let's try a neural network model using stochastic gradient descent, with two hidden layers of 20 neurons. A neural network is comperable in architecture to a perceptron, however with additional hidden layers to allow for more nuanced hypothesis. Maybe the additional nuace will improve our model further. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aFDcZPYTLXg"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "eval_model = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(20, 20), random_state=1)\n",
    "results = evaluate_cutoffs(reviews_bow, reviews_dict, y, range(20,420,20), eval_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hxGWf0vyTMCA"
   },
   "source": [
    "Here our accuracy is even better than in the previous model! There is a plateua around 100 compenents, with an accuracy close to 80% ar around 200 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YUSTc8--g7G"
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrONKuAP-h1b"
   },
   "source": [
    "Of the models presented, the most accurate was the Neural Network. The accuracy was close to 80%, and converged at around 100 components. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwvVTvz2-vE9"
   },
   "source": [
    "**Is Accuracy all that matters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tfU1Jmu5-x2O"
   },
   "source": [
    "Probably not. We don't know exactly how the data is distributed, for all we know only 80% of the ratings were 5 stars and out model always predicts 5 stars. We can get a better idea of the model's performance by looking at its confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqC2yY3lBs_O"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Train model\n",
    "eval_model = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(20, 20), random_state=1)\n",
    "model = LsiModel(reviews_bow, num_topics=100, id2word=reviews_dict)\n",
    "V = densify(model[reviews_bow], len(model.projection.s))\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(V, y, test_size=0.2, random_state = 1911)    \n",
    "eval_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict the outcomes\n",
    "y_pred = eval_model.predict(X_test)\n",
    "\n",
    "#Print confusion matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KE7eX8zxB1P5"
   },
   "source": [
    "How can this be interpreted? Position [i,j] represents the number of times actual rating i was predicted to be rating j. This means the diagonal represents the correct predictions. We have much higher values in our diagonal than elsewhere, meaning we can be more confident that our results are indeed good!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "collapsed_sections": [],
   "name": "545 Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
